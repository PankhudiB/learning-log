## Confluent Kafka 101 course

https://developer.confluent.io/learn-kafka/apache-kafka

event in kafka 
- modelled as key value pair
- internally both are just []byte - loosely typed
- programming language - not so loosely typed

TOPIC
- Event organization
- particular stream of data
- ~ to table in DB without constraints / data validations
- identified by name
- any kind of message format
- seq of message -> stream
- durable set of append only logs
- Can only be seeked by offset, kafka topics are not indexed
  - CANT query topics
- events are immutable 
  - immutability - makes it simpler for replication
- they are durable
  - can be made to expire

PARTITION 
- Topics are split in partitions
- messages within partition are ordered
- Order is guaranteed ONLY WITHIN PARTITION (NOT ACROSS PARTITION) 
- each message within a partition gets incremental id - called Offset
- Data is assigned randomly to a partition unless a key is provided 
- you can have as many partitions for a topic

PRODUCERS
- Producers write data to topics (which are made of partitions)
- Producers know to which partition to write to (and which Kafka broker has it

- Have message key in the message - optional
- if key = null -> data is split across partition using round-robin
- if key! =null, then all messages for that key will always go to the same partition (hashing)
- â€¢ A key are typically sent if you need message ordering for a specific field (ex: truck_id)


MESSAGE :
![img_4.png](img_4.png)

SERIALIZER:
- Kafka accepts only bytes and sends out bytes

KAFKA MESSAGE KEY HASHING:
- Map key to partition 
- default - murmur2 algo
- targetPartition = Math.abs (Utils.murmur2(keyBytes)) % (numPartitions - 1)

CONSUMERS:
- pull model = pull from broker
- 

